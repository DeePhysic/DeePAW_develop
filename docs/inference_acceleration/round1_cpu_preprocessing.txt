================================================================================
第一轮优化：CPU 预处理加速
================================================================================
日期: 2026-02
测试基准: HfO2 80x80x80 网格, 512000 探针点, 12 原子, 24GB GPU

================================================================================
1. 优化前基线分析
================================================================================

使用 cProfile 和自定义 profiling 脚本对 predict_hfo2.py 进行性能分析。

基线耗时分布 (单结构预测):
  - CPU 预处理 (MyCollator.__call__): ~19.2s
  - GPU 推理 (model forward):          ~44s
  - 总计:                               ~63s

CPU 预处理内部热点 (profiling 结果):
  - res_input_constructor:  ~8.9s  (46.5%)  -- 逐点 cKDTree 查询
  - probes_to_graph:        ~5.2s  (27.1%)  -- 超胞构建 + KDTree
  - atoms_to_graph:         ~1.8s  (9.4%)   -- ASE 邻居列表
  - collate_list_of_dicts:  ~1.5s  (7.8%)   -- pad_and_stack
  - 其他:                   ~1.8s  (9.2%)

================================================================================
2. 优化措施
================================================================================

----------------------------------------------------------------------
优化 1: 删除 res_input_constructor 调用
----------------------------------------------------------------------

问题:
  MyCollator.__call__ 中每个 batch 都调用 res_input_constructor()，该函数对每个
  探针点逐一执行 cKDTree.query_ball_point()，时间复杂度 O(N_probes * N_atoms)。
  对于 3000 个探针点，单次调用耗时 ~52ms，171 个 batch 累计 ~8.9s。

  经代码审查，res_input_constructor 生成的 neighbour_atom、num_neighbour_atoms、
  distances、need_fix 四个键在 F_nonlocal 和 F_local 的 forward() 中均未被读取，
  属于历史遗留的死代码。

改动:
  文件: deepaw/data/chgcar_writer.py
  - 删除 MyCollator.__call__ 中对 res_input_constructor() 的调用
  - res_input_constructor 函数本身保留（可能被其他地方引用）

收益: ~8.9s -> 0s (节省 46.5%)
风险: 极低。经验证模型输出不受影响。

----------------------------------------------------------------------
优化 2: 列表推导替换为 np.repeat（probes_to_graph 内部）
----------------------------------------------------------------------

问题:
  probes_to_graph() 中构建 dest_node_idx 使用 Python 列表推导:
    dest_node_idx = np.concatenate([[i]*n for i,n in enumerate(edges_per_probe)])
  对于 3000 个探针点，每次调用耗时 ~10.8ms。

改动:
  文件: deepaw/data/chgcar_writer.py (probes_to_graph 方法)
  - 替换为向量化操作:
    dest_node_idx = np.repeat(np.arange(len(edges_per_probe)), edges_per_probe)

收益: 每 batch ~10.8ms -> ~1.0ms (9.6% 节省)
风险: 无。数学等价替换。

----------------------------------------------------------------------
优化 3: 原子图预计算缓存 (precompute_atom_data + build_graph_with_cache)
----------------------------------------------------------------------

问题:
  原始 probes_to_graph() 每个 batch 都重复计算:
    a) 超胞原子位置 (repeat_offsets, supercell_atom_pos)
    b) 超胞 KDTree 构建
    c) inv_cell_T 矩阵
  这些数据对同一结构的所有 batch 完全相同，属于冗余计算。
  probes_to_graph 每 batch 耗时 ~30ms，其中超胞构建 + KDTree 约占 60%。

改动:
  文件: deepaw/data/chgcar_writer.py
  - 新增 GraphConstructor.precompute_atom_data(atoms) 方法:
    将超胞构建、KDTree、原子图边、tensor 创建等一次性计算并缓存
  - 新增 GraphConstructor.build_graph_with_cache(density, grid_pos, cache) 方法:
    仅构建 probe KDTree 并查询缓存的 atom KDTree，跳过重复计算
  - MyCollator.__call__ 中:
    在 batch 循环外调用 precompute_atom_data()
    循环内改用 build_graph_with_cache()

  文件: deepaw/data/chgcar_writer_huge.py
  - 同样改动

收益: 每 batch ~30ms -> ~18ms (超胞+KDTree 部分从 ~18ms 降到 0)
风险: 低。缓存数据为只读，不影响计算正确性。

----------------------------------------------------------------------
优化 4: 消除单元素 collate_list_of_dicts
----------------------------------------------------------------------

问题:
  MyCollator.__call__ 返回 list_of_dicts 后，DataLoader 会调用
  collate_list_of_dicts() 对每个 batch 的 graph_dict 做 pad_and_stack。
  但由于每个 batch 只包含一个 graph_dict（单结构），pad_and_stack 退化为
  对单元素列表的冗余操作。171 个 batch 累计耗时 ~1.5s。

改动:
  文件: deepaw/data/chgcar_writer.py
  - MyCollator.__call__ 中直接对 graph_dict 做 unsqueeze(0) 添加 batch 维度:
    list_of_dicts.append({k: v.unsqueeze(0) for k, v in graph_dict.items()})
  - 返回 list_of_dicts 而非经过 collate_list_of_dicts 处理的结果

  文件: deepaw/data/chgcar_writer_huge.py
  - 同样改动

收益: ~1.5s -> ~0.1s (7.8% 节省)
风险: 极低。unsqueeze(0) 与 pad_and_stack 对单元素列表结果等价。

================================================================================
3. 优化结果
================================================================================

CPU 预处理耗时对比 (HfO2 80x80x80, 171 batch):

  优化前:  ~19.2s
  优化后:  ~3.9s
  加速比:  4.93x

各优化贡献:
  +-------------------------------+----------+--------+
  | 优化项                        | 节省时间 | 占比   |
  +-------------------------------+----------+--------+
  | 删除 res_input_constructor    | ~8.9s    | 46.5%  |
  | np.repeat 替换列表推导        | ~1.7s    | 9.6%   |
  | 原子图预计算缓存              | ~3.2s    | 16.7%  |
  | 消除单元素 collate            | ~1.5s    | 7.8%   |
  +-------------------------------+----------+--------+
  | 合计                          | ~15.3s   | 79.7%  |
  +-------------------------------+----------+--------+

验证: 预测值范围 [0.025620, 8.122768]，与优化前完全一致。

瓶颈翻转:
  优化前: CPU 预处理 (~19.2s) 占总时间 30%
  优化后: CPU 预处理 (~3.9s)  占总时间 8%
  GPU 推理 (~44s) 成为绝对主导瓶颈 (~80%)

================================================================================
4. 涉及文件
================================================================================

  deepaw/data/chgcar_writer.py      -- 主要改动文件
  deepaw/data/chgcar_writer_huge.py -- 同步改动
  profile_bottleneck.py             -- 性能分析脚本
  profile_deep_dive.py              -- 细粒度分析脚本
