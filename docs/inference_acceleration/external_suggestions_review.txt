================================================================================
外部 16 条优化建议逐条评估
================================================================================
日期: 2026-02
评估基准: 第一轮优化完成后的代码状态

================================================================================
评估结果总览
================================================================================

  已实现（跳过）:    瓶颈 1, 2, 12, 13
  判断有误（跳过）:  瓶颈 5, 6, 10
  收益高估（暂不做）: 瓶颈 3, 9
  需谨慎验证（暂不做）: 瓶颈 15, 16
  值得做（已实施）:  瓶颈 4, 7, 8, 14

================================================================================
一、已实现（第一轮已完成，跳过）
================================================================================

瓶颈 1: 原子图重复计算
  建议: 缓存 atoms_to_graph 结果
  状态: 已实现。precompute_atom_data() 已缓存原子图边和位移。

瓶颈 2: KDTree 重复构建
  建议: 缓存超胞 KDTree
  状态: 已实现。precompute_atom_data() 已缓存 atom_kdtree。

瓶颈 12: res_input_constructor 冗余调用
  建议: 删除或优化 res_input_constructor
  状态: 已实现。该调用已删除（模型不使用其输出）。

瓶颈 13: 单元素 pad_and_stack 开销
  建议: 对单元素列表跳过 pad_and_stack
  状态: 已实现。改用 unsqueeze(0) 替代。

================================================================================
二、判断有误（跳过）
================================================================================

瓶颈 5: probe 位置重复计算
  建议: 缓存 probe 位置
  评估: 不正确。probe 位置每个 batch 不同（不同网格切片），不存在重复计算。

瓶颈 6: 数据库连接开销
  建议: 使用连接池优化数据库访问
  评估: 不正确。数据库连接仅在 MyCollator.__call__ 开头执行一次，
  耗时 <100ms，相对总时间可忽略。

瓶颈 10: tensor 创建操作开销
  建议: 预分配 tensor 避免重复创建
  评估: 不正确。torch.tensor() 调用耗时 <1ms/次，相对 e3nn forward
  (~190ms/batch) 完全可忽略。优化收益远小于代码复杂度增加。

================================================================================
三、收益高估（暂不做）
================================================================================

瓶颈 3: 使用 torch-cluster 进行 GPU 邻居搜索
  建议: 将 KDTree 邻居搜索迁移到 GPU (torch-cluster)
  评估: 当前瓶颈在 GPU 推理 (~44s) 而非 CPU 图构建 (~9s)。
  即使将 CPU 邻居搜索完全消除，总时间仅从 ~55s 降到 ~46s。
  且 torch-cluster 引入额外依赖，安装复杂度高。
  优先级低于 GPU 推理端优化。

瓶颈 9: DataLoader num_workers 并行
  建议: 设置 num_workers > 0 实现数据预取
  评估: 当前 DataLoader batch_size=1（单结构），collate_fn 内部
  已将整个结构拆分为 171 个 sub-batch。num_workers 并行的是
  DataLoader 的 batch 级别，而非 sub-batch 级别。
  设置 num_workers > 0 无法并行化 sub-batch 处理。

================================================================================
四、需谨慎验证（暂不做）
================================================================================

瓶颈 15: torch.compile 加速
  建议: 使用 torch.compile 编译模型
  评估: e3nn 大量使用 TorchScript 和自定义算子，
  与 torch.compile 的兼容性未知。需要实际测试，
  可能遇到 graph break 导致无加速甚至变慢。
  风险较高，建议在有充分测试环境时再尝试。

瓶颈 16: FP16 混合精度推理
  建议: 使用 torch.cuda.amp 进行半精度推理
  评估: 电荷密度预测对数值精度敏感。FP16 的有效精度
  仅 ~3.3 位十进制数，可能导致预测值偏差。
  需要与 DFT 参考值对比验证精度损失是否可接受。
  建议作为可选功能，而非默认行为。

================================================================================
五、值得做（已在第二轮实施）
================================================================================

瓶颈 4: non_blocking 传输
  建议: 使用 non_blocking=True 配合 pin_memory
  评估: 正确且低风险。已实施。
  详见 round2_gpu_inference.txt 优化 2。

瓶颈 7: 模型加载到 GPU
  建议: torch.load 时直接 map_location=device
  评估: 正确且低风险。已实施。
  详见 round2_gpu_inference.txt 优化 3。

瓶颈 8: 增大 batch size
  建议: 增大 probe batch size 以减少 kernel launch 开销
  评估: 方向正确，但受 GPU 显存限制。
  已实现可配置化，默认值保持 3000。
  详见 round2_gpu_inference.txt 优化 1。

瓶颈 14: 部分 dtype 优化 (int64->int32)
  建议: 将边索引从 int64 降为 int32
  评估: 经代码验证不可行。scatter_add_ 要求 int64。
  详见 round2_gpu_inference.txt "未采纳" 部分。
