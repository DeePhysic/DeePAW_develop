================================================================================
DeePAW 模型推理加速 - 总结与未来方向
================================================================================
日期: 2026-02
测试基准: HfO2 80x80x80 网格, 512000 探针点, 12 原子, 24GB GPU

================================================================================
1. 两轮优化总结
================================================================================

第一轮: CPU 预处理加速
  目标: 消除 MyCollator.__call__ 中的冗余计算
  方法: 删除死代码、向量化、缓存、消除冗余 collate
  结果: CPU 预处理 19.2s -> 3.9s (4.93x 加速)

  具体措施:
    1. 删除 res_input_constructor 调用 (节省 46.5%)
    2. np.repeat 替换列表推导 (节省 9.6%)
    3. 原子图预计算缓存 (节省 16.7%)
    4. 消除单元素 collate (节省 7.8%)

第二轮: GPU 推理端与传输优化
  目标: 减少数据传输开销、消除无用计算
  方法: non_blocking 传输、直接加载到 GPU、inference 模式、batch size 可配置
  结果: 传输和加载环节有小幅改善，GPU 推理本身未变

  具体措施:
    1. batch size 可配置化 (默认 3000，用户可调)
    2. non_blocking 传输 + 排除推理无关键
    3. 模型权重直接加载到目标设备
    4. inference 模式跳过无用 tensor 创建

================================================================================
2. 耗时对比
================================================================================

HfO2 80x80x80 单结构预测耗时:

  +------------------+--------+--------+--------+
  | 阶段             | 优化前 | 第一轮 | 第二轮 |
  +------------------+--------+--------+--------+
  | CPU 预处理       | 19.2s  |  3.9s  | ~9s*   |
  | GPU 推理         | 44s    |  44s   | ~44s   |
  | 模型加载         | ~5s    |  ~5s   | ~2s    |
  +------------------+--------+--------+--------+

  * 第二轮 CPU 预处理含数据库 I/O，实际图构建部分 ~3.9s 不变

================================================================================
3. 当前瓶颈分析
================================================================================

GPU 推理占总时间 ~80%，为绝对主导瓶颈。

GPU 推理耗时构成 (每 batch ~190ms):
  - e3nn tensor product (球谐张量积): ~120ms (63%)
  - scatter 聚合操作:                 ~30ms  (16%)
  - 径向基函数计算:                   ~15ms  (8%)
  - 线性层 + Gate 激活:               ~15ms  (8%)
  - 其他 (数据搬运等):               ~10ms  (5%)

核心瓶颈在 e3nn 的 TensorProduct 算子。该算子的计算量与
mul (500) * lmax (4) 的组合数成正比，是模型精度的基础，
无法在不影响精度的前提下简单优化。

================================================================================
4. 未来优化方向
================================================================================

以下方向按可行性和预期收益排序:

----------------------------------------------------------------------
方向 1: torch.compile (中等风险，潜在高收益)
----------------------------------------------------------------------

  思路: PyTorch 2.0+ 的 torch.compile 可自动融合算子、减少 kernel launch。
  预期: 对 e3nn 的 TensorProduct 可能有 20-50% 加速。
  风险: e3nn 内部使用 TorchScript，可能与 torch.compile 冲突，
        导致 graph break 或编译失败。
  建议: 在测试环境中尝试 torch.compile(model, mode="reduce-overhead")，
        观察是否有 graph break 警告。

----------------------------------------------------------------------
方向 2: FP16 混合精度推理 (中等风险，中等收益)
----------------------------------------------------------------------

  思路: 使用 torch.cuda.amp.autocast 进行半精度推理，
        理论上可将 GPU 计算吞吐量翻倍。
  预期: 20-40% 加速（取决于算子对 FP16 的支持程度）。
  风险: 电荷密度预测对数值精度敏感，FP16 有效精度仅
        ~3.3 位十进制数，可能导致预测偏差。
  建议: 先用 BF16（精度更好）测试，对比 MAE 变化。
        如果 MAE 增加 <1%，可作为可选加速模式。

----------------------------------------------------------------------
方向 3: 减小模型规模 (高风险，高收益)
----------------------------------------------------------------------

  思路: 降低 mul (500->256) 或 lmax (4->3) 减少计算量。
  预期: mul 减半可带来 ~2x 加速，lmax 降 1 级约 30% 加速。
  风险: 直接影响模型表达能力，需要重新训练并验证精度。
  建议: 作为长期方向，训练多个规模的模型供用户选择
        (如 fast/balanced/accurate 三档)。

----------------------------------------------------------------------
方向 4: 使用更大显存 GPU 增大 batch size (低风险，中等收益)
----------------------------------------------------------------------

  思路: 在 A100 (40/80GB) 上将 batch size 从 3000 提升到 10000+，
        减少 70%+ 的 kernel launch 和数据传输开销。
  预期: 10-20% 总时间加速（主要减少固定开销）。
  风险: 极低。已实现 data_batch_size 可配置接口。
  建议: 在大显存 GPU 上测试不同 batch size，找到最优值。

================================================================================
5. 所有涉及文件总览
================================================================================

  deepaw/data/chgcar_writer.py        -- 第一轮 + 第二轮核心改动
  deepaw/data/chgcar_writer_huge.py   -- 同步改动
  examples/predict_hfo2.py            -- 第二轮预测脚本改动
  deepaw/scripts/predict_chgcar.py    -- 第二轮预测脚本改动
  deepaw/scripts/predict_chgcar_dual.py -- 第二轮预测脚本改动
  profile_bottleneck.py               -- 性能分析工具
  profile_deep_dive.py                -- 细粒度分析工具
